{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertModel, BertConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "configuration = BertConfig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BertModel(configuration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "configuration = model.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertConfig {\n",
       "  \"attention_probs_dropout_prob\": 0.1,\n",
       "  \"gradient_checkpointing\": false,\n",
       "  \"hidden_act\": \"gelu\",\n",
       "  \"hidden_dropout_prob\": 0.1,\n",
       "  \"hidden_size\": 768,\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"intermediate_size\": 3072,\n",
       "  \"layer_norm_eps\": 1e-12,\n",
       "  \"max_position_embeddings\": 512,\n",
       "  \"model_type\": \"bert\",\n",
       "  \"num_attention_heads\": 12,\n",
       "  \"num_hidden_layers\": 12,\n",
       "  \"pad_token_id\": 0,\n",
       "  \"type_vocab_size\": 2,\n",
       "  \"vocab_size\": 30522\n",
       "}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 768)\n",
       "    (token_type_embeddings): Embedding(2, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (6): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (7): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (8): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (9): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (10): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (11): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): BertPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b2891d246c649b6a2fd888129ecc5f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer(\"Hello, my dog is cute\", return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[  101,  7592,  1010,  2026,  3899,  2003, 10140,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe8df470401f41b39ed8cbb83a2e8dea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=433.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b1c61f4a1c94c52acf4d109e7e6aad1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=440473133.0, style=ProgressStyle(descri…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model = BertModel.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 768)\n",
       "    (token_type_embeddings): Embedding(2, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (6): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (7): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (8): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (9): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (10): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (11): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): BertPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = model(**inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[-0.1144,  0.1937,  0.1250,  ..., -0.3827,  0.2107,  0.5407],\n",
       "          [ 0.5308,  0.3207,  0.3665,  ..., -0.0036,  0.7579,  0.0388],\n",
       "          [-0.4877,  0.8849,  0.4256,  ..., -0.6976,  0.4458,  0.1231],\n",
       "          ...,\n",
       "          [-0.7003, -0.1815,  0.3297,  ..., -0.4838,  0.0680,  0.8901],\n",
       "          [-1.0355, -0.2567, -0.0317,  ...,  0.3197,  0.3999,  0.1795],\n",
       "          [ 0.6080,  0.2610, -0.3131,  ...,  0.0311, -0.6283, -0.1994]]],\n",
       "        grad_fn=<NativeLayerNormBackward>),\n",
       " tensor([[-7.1946e-01, -2.1445e-01, -2.9576e-01,  3.6603e-01,  2.7968e-01,\n",
       "           2.2183e-02,  5.7299e-01,  6.2331e-02,  5.9586e-02, -9.9965e-01,\n",
       "           5.0146e-02,  4.4756e-01,  9.7612e-01,  3.3989e-02,  8.4494e-01,\n",
       "          -3.6905e-01,  9.8649e-02, -3.7169e-01,  1.7371e-01,  1.1515e-01,\n",
       "           4.4133e-01,  9.9525e-01,  3.7221e-01,  8.2881e-02,  2.1402e-01,\n",
       "           6.8965e-01, -6.1042e-01,  8.7136e-01,  9.4158e-01,  5.7372e-01,\n",
       "          -3.2187e-01,  8.6673e-03, -9.8611e-01, -2.0542e-02, -4.3756e-01,\n",
       "          -9.8012e-01,  1.1142e-01, -6.7587e-01,  1.3499e-01,  3.1130e-01,\n",
       "          -8.2997e-01,  1.9006e-01,  9.9896e-01, -3.1798e-01,  2.1517e-02,\n",
       "          -1.6531e-01, -9.9943e-01,  1.0173e-01, -8.1811e-01,  3.3120e-02,\n",
       "           3.6740e-01, -7.3229e-02, -1.4261e-01,  1.8907e-01,  2.6119e-01,\n",
       "           4.1582e-01, -2.4427e-01, -5.9846e-02, -7.3492e-02, -3.4202e-01,\n",
       "          -5.8001e-01,  2.8331e-01, -5.0513e-01, -8.1967e-01,  1.9813e-01,\n",
       "           1.9108e-01,  3.7011e-02, -1.1327e-01,  1.3472e-01, -2.1614e-01,\n",
       "           6.3494e-01,  2.4869e-02,  3.8287e-01, -8.1779e-01, -2.4874e-01,\n",
       "           8.4982e-02, -5.2998e-01,  1.0000e+00, -5.2155e-02, -9.7052e-01,\n",
       "           3.9848e-01,  2.1360e-02,  3.9035e-01,  3.5588e-01, -1.7881e-01,\n",
       "          -9.9997e-01,  2.6939e-01, -3.8057e-02, -9.8657e-01,  6.9322e-02,\n",
       "           3.9138e-01, -2.1885e-02, -9.6331e-02,  3.8545e-01, -3.4136e-01,\n",
       "          -8.0362e-02, -3.2023e-02, -3.6328e-01, -7.8130e-02,  1.9192e-02,\n",
       "          -1.3429e-01, -1.6013e-02, -5.2640e-02, -2.8006e-01,  9.3612e-02,\n",
       "          -2.2885e-01, -1.2305e-01, -1.1002e-01, -3.2808e-01,  4.0356e-01,\n",
       "           2.8048e-01, -2.0102e-01,  2.7685e-01, -9.4023e-01,  4.1756e-01,\n",
       "          -1.5473e-01, -9.7553e-01, -4.3003e-01, -9.8546e-01,  5.9158e-01,\n",
       "           3.7344e-02, -1.9320e-01,  9.1691e-01,  3.6012e-01,  1.4505e-01,\n",
       "           1.5398e-01, -1.0658e-02, -1.0000e+00, -3.1573e-01, -3.1037e-01,\n",
       "           1.6523e-01, -8.0330e-02, -9.6650e-01, -9.4546e-01,  3.6145e-01,\n",
       "           9.0138e-01, -7.2696e-02,  9.9774e-01,  3.7289e-02,  9.3599e-01,\n",
       "           2.5317e-01, -2.0185e-01,  2.9533e-02, -2.3163e-01,  3.4632e-01,\n",
       "          -1.0763e-01, -2.6565e-01,  1.0874e-01,  1.2985e-01,  2.1135e-02,\n",
       "          -9.6283e-02, -7.6358e-02, -6.5149e-02, -8.9277e-01, -2.3465e-01,\n",
       "           9.1176e-01,  7.0429e-02, -2.1429e-01,  3.8197e-01,  3.5892e-02,\n",
       "          -1.6971e-01,  7.0654e-01,  2.4045e-01,  1.5014e-01, -1.9478e-02,\n",
       "           2.1369e-01, -1.7977e-01,  3.5112e-01, -6.0260e-01,  4.1683e-01,\n",
       "           1.8090e-01, -3.2497e-02, -3.0138e-01, -9.7103e-01, -1.3917e-01,\n",
       "           3.5130e-01,  9.8326e-01,  5.2702e-01,  4.8812e-02,  1.3991e-02,\n",
       "          -6.7964e-02,  2.9718e-01, -9.4136e-01,  9.7219e-01, -2.4774e-02,\n",
       "           1.5224e-01, -1.8241e-01,  5.5584e-02, -7.7306e-01, -9.9000e-02,\n",
       "           4.7058e-01, -1.7022e-01, -7.7803e-01,  5.2833e-02, -3.7679e-01,\n",
       "          -4.1296e-02, -4.9612e-01,  1.4171e-01, -1.1803e-01, -1.8995e-01,\n",
       "           5.0383e-02,  9.0623e-01,  7.8828e-01,  5.2288e-01, -3.5274e-01,\n",
       "           2.8563e-01, -8.1494e-01, -1.9622e-01, -9.2975e-02,  5.9311e-02,\n",
       "           3.1903e-02,  9.8860e-01, -3.9452e-01,  1.1867e-01, -8.6977e-01,\n",
       "          -9.7789e-01, -1.4859e-01, -7.7064e-01, -4.0619e-03, -4.1152e-01,\n",
       "           3.2578e-01,  1.8777e-01, -2.4501e-01,  2.6668e-01, -7.9329e-01,\n",
       "          -4.8133e-01,  9.3246e-02, -1.7010e-01,  2.7043e-01, -3.5880e-02,\n",
       "           7.7973e-01,  4.6697e-01, -3.4636e-01,  5.5239e-02,  9.0312e-01,\n",
       "          -2.4115e-01, -6.4200e-01,  4.1441e-01, -9.7797e-02,  6.2983e-01,\n",
       "          -4.1787e-01,  9.4069e-01,  4.9285e-01,  3.6058e-01, -8.7901e-01,\n",
       "          -2.6726e-01, -5.4679e-01,  9.3899e-04, -1.0502e-02, -4.6837e-01,\n",
       "           3.1116e-01,  3.6999e-01,  1.3306e-01,  6.4092e-01, -3.5630e-01,\n",
       "           8.8549e-01, -8.9036e-01, -9.3865e-01, -8.1215e-01,  2.7362e-01,\n",
       "          -9.8566e-01,  4.0363e-01,  2.1223e-01, -1.4316e-01, -2.4553e-01,\n",
       "          -2.1144e-01, -9.4728e-01,  5.0806e-01, -9.6621e-02,  8.5571e-01,\n",
       "          -1.0133e-01, -6.7768e-01, -2.8500e-01, -8.9905e-01, -3.3577e-01,\n",
       "           8.9155e-02,  3.2600e-01, -2.6467e-01, -9.2032e-01,  3.4629e-01,\n",
       "           3.3430e-01,  2.1397e-01,  3.0629e-02,  9.3878e-01,  9.9986e-01,\n",
       "           9.6385e-01,  8.3159e-01,  6.2250e-01, -9.8055e-01, -7.3623e-01,\n",
       "           9.9986e-01, -7.8395e-01, -9.9998e-01, -8.7800e-01, -5.0893e-01,\n",
       "           2.3399e-02, -1.0000e+00, -6.1938e-02,  1.9563e-01, -9.0552e-01,\n",
       "          -1.4008e-01,  9.5264e-01,  7.9837e-01, -1.0000e+00,  7.6343e-01,\n",
       "           8.3670e-01, -4.5859e-01,  5.4410e-01, -2.4073e-01,  9.6085e-01,\n",
       "           1.9164e-01,  3.2135e-01, -1.3064e-02,  2.4534e-01, -5.3001e-01,\n",
       "          -5.9538e-01,  3.7464e-01, -2.1189e-01,  8.8024e-01,  1.9648e-02,\n",
       "          -3.8349e-01, -8.4779e-01,  1.4677e-02, -2.8376e-02, -4.4313e-01,\n",
       "          -9.4966e-01, -6.5704e-02, -7.2327e-02,  6.5967e-01, -1.1504e-01,\n",
       "           2.1876e-01, -5.5254e-01,  9.2219e-02, -5.0583e-01, -5.2825e-02,\n",
       "           5.1425e-01, -8.9533e-01, -1.2744e-01,  9.7845e-02, -6.0145e-01,\n",
       "          -3.1652e-02, -9.5186e-01,  9.4685e-01, -2.2341e-01,  1.8390e-01,\n",
       "           1.0000e+00,  1.1755e-01, -7.0390e-01,  3.2502e-01, -1.0898e-02,\n",
       "          -1.8308e-01,  9.9999e-01,  5.8376e-01, -9.7387e-01, -3.3783e-01,\n",
       "           2.9640e-01, -2.7002e-01, -2.2243e-01,  9.9711e-01,  1.4422e-02,\n",
       "           7.8268e-02,  3.8660e-01,  9.7787e-01, -9.8501e-01,  8.7459e-01,\n",
       "          -7.2276e-01, -9.5249e-01,  9.4567e-01,  9.1005e-01, -5.0722e-01,\n",
       "          -4.9026e-01, -1.2517e-01, -3.9077e-02,  8.8128e-02, -8.2482e-01,\n",
       "           3.8301e-01,  1.8045e-01,  5.4796e-02,  8.0041e-01, -3.3501e-01,\n",
       "          -3.9115e-01,  1.4233e-01, -9.0141e-02,  3.4585e-01,  4.4044e-01,\n",
       "           3.1045e-01, -1.3280e-01, -1.3614e-01, -3.0303e-01, -4.8794e-01,\n",
       "          -9.4950e-01,  1.0887e-01,  1.0000e+00,  6.0752e-02,  8.3374e-02,\n",
       "          -3.1305e-03,  8.5578e-02, -3.1288e-01,  2.6283e-01,  2.6870e-01,\n",
       "          -1.4267e-01, -7.4000e-01,  2.2856e-01, -7.9442e-01, -9.8812e-01,\n",
       "           4.3592e-01,  7.7230e-02, -3.8084e-02,  9.9490e-01,  3.2616e-01,\n",
       "           6.7989e-02,  8.2888e-02,  4.7391e-01, -2.1855e-01,  3.9278e-01,\n",
       "           3.7666e-02,  9.6440e-01, -1.8374e-01,  3.9259e-01,  4.3319e-01,\n",
       "          -1.8618e-01, -2.1584e-01, -4.9610e-01, -9.7025e-02, -8.8006e-01,\n",
       "           2.4995e-01, -9.3940e-01,  9.3827e-01,  3.2001e-01,  1.1919e-01,\n",
       "           7.3959e-02,  3.1273e-02,  1.0000e+00, -7.5631e-01,  3.5396e-01,\n",
       "           5.3290e-01,  3.2036e-01, -9.7538e-01, -4.7482e-01, -2.3322e-01,\n",
       "           3.5376e-02, -4.6060e-02, -1.2863e-01,  8.3798e-02, -9.5139e-01,\n",
       "           3.4663e-02,  4.5221e-03, -8.8296e-01, -9.8300e-01,  1.6468e-01,\n",
       "           3.3596e-01, -1.0217e-01, -7.0275e-01, -4.3307e-01, -5.4169e-01,\n",
       "           1.8884e-01, -5.5797e-02, -9.2162e-01,  4.4790e-01, -3.5256e-02,\n",
       "           2.1131e-01, -4.6267e-02,  4.1688e-01,  1.9311e-01,  8.2643e-01,\n",
       "           3.1896e-02,  1.8036e-02,  2.2502e-02, -5.6261e-01,  5.2690e-01,\n",
       "          -4.1523e-01, -2.0335e-01,  5.0973e-03,  1.0000e+00, -1.3769e-01,\n",
       "           4.0090e-01,  4.8581e-01,  3.0547e-01,  1.0161e-01,  1.1372e-01,\n",
       "           5.4688e-01,  1.7282e-01, -1.1611e-01,  1.1691e-01,  3.3706e-01,\n",
       "          -9.4995e-02,  3.3125e-01, -1.1600e-01,  5.5663e-02,  6.9017e-01,\n",
       "           5.2775e-01, -7.8248e-02,  7.7874e-02, -2.5570e-01,  9.5441e-01,\n",
       "           4.4725e-02,  7.5062e-02, -1.6521e-01,  9.8572e-02, -1.2673e-01,\n",
       "           4.2396e-01,  9.9999e-01,  1.4012e-01, -6.5117e-02, -9.8683e-01,\n",
       "          -3.4659e-01, -6.9549e-01,  9.9968e-01,  7.8693e-01, -6.2560e-01,\n",
       "           4.0561e-01,  5.1398e-01, -7.1928e-03,  3.7469e-01, -4.9920e-02,\n",
       "          -1.8379e-01,  1.0699e-01,  6.4271e-02,  9.4363e-01, -4.5982e-01,\n",
       "          -9.6684e-01, -4.8714e-01,  1.6233e-01, -9.2982e-01,  9.8976e-01,\n",
       "          -2.8241e-01, -3.9526e-02, -2.8969e-01,  2.2178e-01, -7.3322e-01,\n",
       "          -1.9752e-01, -9.7385e-01,  1.4625e-01,  1.7384e-02,  9.4459e-01,\n",
       "           8.0070e-02, -4.1026e-01, -7.2363e-01,  6.5495e-02,  2.9531e-01,\n",
       "          -2.0402e-01, -9.4453e-01,  9.4867e-01, -9.6224e-01,  4.1987e-01,\n",
       "           9.9992e-01,  2.0182e-01, -5.9719e-01,  6.7062e-02, -1.3560e-01,\n",
       "           1.1140e-01, -7.1071e-02,  3.3843e-01, -9.1928e-01, -1.1785e-01,\n",
       "           7.1901e-03,  9.3813e-02,  1.2718e-01, -4.2175e-01,  6.2383e-01,\n",
       "          -3.0948e-02, -3.9573e-01, -4.9911e-01,  1.9713e-01,  1.9574e-01,\n",
       "           5.2774e-01, -6.4999e-02,  3.8218e-02, -1.3764e-01,  1.3114e-01,\n",
       "          -8.2896e-01, -6.2802e-02, -1.3078e-01, -9.9745e-01,  3.8189e-01,\n",
       "          -1.0000e+00, -4.9528e-02, -3.3011e-01, -9.7049e-03,  7.4032e-01,\n",
       "           4.5588e-01, -4.3038e-02, -5.9485e-01,  3.5138e-02,  8.4290e-01,\n",
       "           7.0024e-01,  4.9501e-03,  1.5221e-01, -4.8182e-01,  3.4912e-02,\n",
       "           6.8681e-02,  5.9797e-02,  9.4147e-02,  5.7532e-01,  3.5063e-02,\n",
       "           1.0000e+00, -4.4783e-03, -3.4757e-01, -7.9309e-01,  5.7241e-02,\n",
       "          -4.8241e-02,  9.9991e-01, -3.6963e-01, -9.2729e-01,  2.2610e-01,\n",
       "          -3.2602e-01, -6.5948e-01,  2.3506e-01, -6.6026e-02, -6.2875e-01,\n",
       "          -4.7124e-01,  8.3105e-01,  4.3462e-01, -5.2237e-01,  2.1811e-01,\n",
       "          -1.1176e-01, -2.7027e-01, -6.8502e-02,  5.0503e-02,  9.8319e-01,\n",
       "           3.3888e-01,  5.6442e-01,  1.0517e-01,  6.1441e-02,  9.3666e-01,\n",
       "           7.3988e-02, -2.4528e-01, -8.5207e-02,  9.9998e-01,  1.4210e-01,\n",
       "          -8.2488e-01,  2.2405e-01, -9.2098e-01, -1.0235e-01, -8.4105e-01,\n",
       "           2.1140e-01, -3.4107e-02,  8.0942e-01,  4.9840e-03,  8.9624e-01,\n",
       "           6.7185e-02, -1.7137e-01, -2.7561e-01,  2.6385e-01,  1.9073e-01,\n",
       "          -8.6307e-01, -9.8238e-01, -9.8035e-01,  2.2370e-01, -3.5154e-01,\n",
       "           1.9181e-01,  8.9503e-02, -9.8139e-02,  8.3593e-02,  3.0373e-01,\n",
       "          -9.9998e-01,  9.0944e-01,  2.9007e-01,  4.4585e-01,  9.4631e-01,\n",
       "           4.1260e-01,  1.9621e-01,  2.4693e-01, -9.7562e-01, -7.6957e-01,\n",
       "          -1.7996e-01, -5.8601e-02,  4.2949e-01,  3.3341e-01,  8.0548e-01,\n",
       "           2.5306e-01, -4.0736e-01, -3.4586e-02,  4.1000e-01, -8.3874e-01,\n",
       "          -9.9092e-01,  3.0937e-01,  3.3917e-01, -6.2679e-01,  9.4565e-01,\n",
       "          -5.9613e-01, -1.9439e-03,  3.7971e-01, -2.2250e-01,  5.2158e-01,\n",
       "           5.9324e-01, -1.8357e-02, -6.7999e-03,  2.1554e-01,  8.2484e-01,\n",
       "           8.0068e-01,  9.7795e-01, -1.0868e-01,  4.3963e-01,  2.2388e-01,\n",
       "           2.7078e-01,  8.5065e-01, -9.2567e-01,  4.3629e-03, -3.2062e-02,\n",
       "          -1.9565e-01,  1.1169e-01, -9.4711e-02, -7.2645e-01,  6.3986e-01,\n",
       "          -1.7955e-01,  4.2939e-01, -2.0787e-01,  2.2294e-01, -2.3857e-01,\n",
       "           6.7195e-02, -5.1772e-01, -3.6389e-01,  5.3170e-01,  5.3485e-02,\n",
       "           8.5309e-01,  6.4611e-01,  1.2341e-02, -2.4756e-01,  1.4718e-02,\n",
       "          -5.3294e-02, -9.2566e-01,  5.0771e-01,  1.2492e-01,  2.1457e-01,\n",
       "          -6.7959e-02, -2.7113e-01,  9.0946e-01, -1.9032e-01, -2.1274e-01,\n",
       "          -6.4847e-02, -4.3871e-01,  6.3752e-01, -2.1017e-01, -2.9291e-01,\n",
       "          -3.1616e-01,  5.4117e-01,  1.6768e-01,  9.9424e-01, -9.4509e-02,\n",
       "          -2.9022e-01, -2.1881e-03, -1.5720e-01,  2.8317e-01, -2.9364e-01,\n",
       "          -9.9998e-01,  1.4066e-01,  9.1605e-02,  1.1458e-01, -2.1965e-01,\n",
       "           3.0746e-01, -5.7720e-02, -8.7692e-01, -9.3891e-02,  2.2809e-01,\n",
       "           3.8767e-02, -3.2828e-01, -3.1138e-01,  4.1117e-01,  4.6004e-01,\n",
       "           5.5266e-01,  7.2535e-01,  2.5635e-01,  5.2958e-01,  4.7964e-01,\n",
       "          -1.0402e-01, -5.4204e-01,  8.4934e-01]], grad_fn=<TanhBackward>))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_hidden_states = outputs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_scores, seq_relationship_scores = outputs[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertForNextSentencePrediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForNextSentencePrediction: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForNextSentencePrediction from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing BertForNextSentencePrediction from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "model = BertForNextSentencePrediction.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"In Italy, pizza served in formal settings, such as at a restaurant, is presented unsliced.\"\n",
    "next_sentence = \"The sky is blue due to the shorter wavelength of blue light.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding = tokenizer(prompt, next_sentence, return_tensors='pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[  101,  1999,  3304,  1010, 10733,  2366,  1999,  5337, 10906,  1010,\n",
       "          2107,  2004,  2012,  1037,  4825,  1010,  2003,  3591,  4895, 14540,\n",
       "          6610,  2094,  1012,   102,  1996,  3712,  2003,  2630,  2349,  2000,\n",
       "          1996,  7820, 19934,  1997,  2630,  2422,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, logits = model(**encoding, next_sentence_label=torch.LongTensor([1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert logits[0, 0] < logits[0, 1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
